{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HjsfDFjHJLz9"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, Dense, Reshape, Flatten, Dropout, LeakyReLU, Conv2DTranspose, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import backend as K\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8d6V_if0JLz_"
      },
      "outputs": [],
      "source": [
        "# Load MNIST data\n",
        "(X_train, _), (_, _) = mnist.load_data()\n",
        "X_train = X_train / 255.0  # Normalize to [0, 1]\n",
        "X_train = np.expand_dims(X_train, axis=-1)\n",
        "X_train, X_test = train_test_split(X_train, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dxkAe37FJLz_"
      },
      "outputs": [],
      "source": [
        "print(X_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FonP1m5fJLz_"
      },
      "outputs": [],
      "source": [
        "# Generator model\n",
        "def build_generator(z_dim):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(7*7*256, input_dim=z_dim))\n",
        "    model.add(Reshape((7, 7, 256)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "    model.add(Conv2DTranspose(128, kernel_size=4, strides=2, padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "    model.add(Conv2DTranspose(64, kernel_size=4, strides=2, padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "    model.add(Conv2DTranspose(1, kernel_size=4, strides=1, padding='same', activation='tanh'))\n",
        "    return model\n",
        "\n",
        "# Discriminator model\n",
        "def build_discriminator(img_shape):\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(64, kernel_size=4, strides=2, padding='same', input_shape=img_shape))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Dropout(0.3))\n",
        "\n",
        "    model.add(Conv2D(128, kernel_size=4, strides=2, padding='same'))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Dropout(0.3))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ecs4yTSJL0A"
      },
      "outputs": [],
      "source": [
        "# Define GAN components\n",
        "batch_size = 256\n",
        "z_dim = 100\n",
        "wasserstein_loss = lambda y_true, y_pred: K.mean(y_true * y_pred)\n",
        "lambda_gp = 10\n",
        "epsilon = tf.random.uniform(shape=[batch_size, 1, 1, 1], minval=0, maxval=1)\n",
        "\n",
        "# Initialize models\n",
        "generator = build_generator(z_dim)\n",
        "discriminator = build_discriminator((28, 28, 1))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NoKDTfXzJL0A"
      },
      "outputs": [],
      "source": [
        "generator.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_T5p_GTGa7kv"
      },
      "outputs": [],
      "source": [
        "def gradient_penalty(discriminator, real_imgs, fake_imgs, epsilon, batch_size):\n",
        "    interpolated_imgs = epsilon * tf.cast(real_imgs, tf.float32) + ((1 - epsilon) * tf.cast(fake_imgs, tf.float32))\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        tape.watch(interpolated_imgs)\n",
        "        pred = discriminator(interpolated_imgs, training = True)\n",
        "\n",
        "    gradients = tape.gradient(pred, [interpolated_imgs])[0]\n",
        "    grad_norms = tf.sqrt(tf.reduce_sum(tf.square(gradients), axis=[1, 2, 3]))\n",
        "    gradient_penalty = tf.reduce_mean(tf.square(grad_norms - 1))\n",
        "\n",
        "    return gradient_penalty\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G4IQTo9JJL0A"
      },
      "outputs": [],
      "source": [
        "# Function to plot generated images\n",
        "def plot_generated_images(generator, epoch, z_dim, examples=16, dim=(4, 4), figsize=(10, 10)):\n",
        "    noise = np.random.normal(0, 1, size=[examples, z_dim])\n",
        "    generated_images = generator.predict(noise)\n",
        "    generated_images = generated_images.reshape(examples, 28, 28)\n",
        "\n",
        "    plt.figure(figsize=figsize)\n",
        "    for i in range(examples):\n",
        "        plt.subplot(dim[0], dim[1], i + 1)\n",
        "        plt.imshow(generated_images[i], interpolation='nearest', cmap='gray')\n",
        "        plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f'gan_output_sample_{epoch}.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jEe89n78u8f5"
      },
      "outputs": [],
      "source": [
        "gen_optimizer = Adam(learning_rate=0.0002, beta_1=0.5, beta_2=0.9)\n",
        "critic_optimizer = Adam(learning_rate=0.0002, beta_1=0.5, beta_2=0.9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def show_losses(critic_losses, gen_losses):\n",
        "    # Plot losses\n",
        "    plt.figure(figsize=(7, 3))\n",
        "    plt.plot(critic_losses, label='Critic Loss')\n",
        "    plt.plot(gen_losses, label='Generator Loss')\n",
        "    plt.xlabel('Batch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EsulnIYFJL0A"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def train_critic(discriminator, critic_optimizer, real_imgs, fake_imgs):\n",
        "    # Train discriminator\n",
        "    with tf.GradientTape() as tape:\n",
        "        critic_loss_real = discriminator(real_imgs)\n",
        "        critic_loss_fake = discriminator(fake_imgs)\n",
        "        gp = gradient_penalty(discriminator, real_imgs, fake_imgs, epsilon, batch_size)\n",
        "        critic_loss = tf.reduce_mean(critic_loss_fake) - tf.reduce_mean(critic_loss_real) + (lambda_gp * gp)\n",
        "    gradients = tape.gradient(critic_loss, discriminator.trainable_variables)\n",
        "    critic_optimizer.apply_gradients(zip(gradients, discriminator.trainable_variables))\n",
        "    return critic_loss\n",
        "\n",
        "@tf.function\n",
        "def train_generator(generator, discriminator, gen_optimizer):\n",
        "    z = np.random.randn(batch_size, z_dim)\n",
        "    valid_y = np.ones((batch_size, 1))\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        critic_pred = discriminator(generator(z), training = True)\n",
        "        g_loss = -tf.reduce_mean(critic_pred)\n",
        "    gradients = tape.gradient(g_loss, generator.trainable_variables)\n",
        "    gen_optimizer.apply_gradients(zip(gradients, generator.trainable_variables))\n",
        "    return g_loss\n",
        "\n",
        "# Training function\n",
        "def train_wgan(generator, discriminator, epochs=100, batch_size=64, n_critic_train = 3):\n",
        "    critic_losses, gen_losses = [], []\n",
        "\n",
        "    # Calculate number of batches per epoch\n",
        "    num_batches = X_train.shape[0] // batch_size\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        np.random.shuffle(X_train)\n",
        "        print(f\"Epoch {epoch}\")\n",
        "        n_critic_count = 1\n",
        "        for batch in range(num_batches):\n",
        "            real_imgs = X_train[batch * batch_size: (batch * batch_size) + batch_size]\n",
        "            z = np.random.randn(batch_size, z_dim)\n",
        "            fake_imgs = generator.predict(z)\n",
        "\n",
        "            # Train critic\n",
        "            critic_loss = train_critic(discriminator, critic_optimizer, real_imgs, fake_imgs)\n",
        "            n_critic_count += 1\n",
        "\n",
        "            if n_critic_count > n_critic_train:\n",
        "                # Train generator\n",
        "                g_loss = train_generator(generator, discriminator, gen_optimizer)\n",
        "                n_critic_count = 1\n",
        "                # Save gen losses\n",
        "                gen_losses.append(g_loss)\n",
        "\n",
        "            # Save critic losses\n",
        "            critic_losses.append(critic_loss)\n",
        "\n",
        "        # Print progress\n",
        "        # os.system('cls' if os.name == 'nt' else 'clear')\n",
        "        print(f\"D Loss: {np.mean(critic_losses)}, G Loss: {np.mean(gen_losses)}\")\n",
        "        plot_generated_images(generator, epoch, z_dim)\n",
        "        show_losses(critic_losses, gen_losses)\n",
        "\n",
        "    return critic_losses, gen_losses\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E3pfJSeIs1-X"
      },
      "outputs": [],
      "source": [
        "# Train DCGAN\n",
        "D_losses, g_losses = train_wgan(generator, discriminator, epochs = 10, batch_size = batch_size, n_critic_train=3)\n",
        "\n",
        "# Save the generator model\n",
        "generator.save('simple_gan_generator.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xpuekLAVJL0A"
      },
      "outputs": [],
      "source": [
        "\n",
        "def generate_images(generator, z_points):\n",
        "    \"\"\"Generate images from z-space points using the generator.\"\"\"\n",
        "    images = generator.predict(z_points)\n",
        "    return images\n",
        "\n",
        "# Generate random points in z-space\n",
        "z_dim = 100  # Dimension of the z-space (latent space)\n",
        "num_samples = 16  # Number of images to generate\n",
        "z_points = np.random.randn(num_samples, z_dim)\n",
        "\n",
        "# Generate images from these points\n",
        "generated_images = generate_images(generator, z_points)\n",
        "\n",
        "# Plot the generated images\n",
        "fig, axes = plt.subplots(4, 4, figsize=(10, 10))\n",
        "for i, ax in enumerate(axes.flatten()):\n",
        "    ax.imshow(generated_images[i].reshape(28, 28), cmap='gray')\n",
        "    ax.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MHgqxQZhJL0A"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
